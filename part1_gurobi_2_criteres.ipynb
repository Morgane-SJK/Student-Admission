{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM - Système de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE 1 : Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from gurobipy import Model\n",
    "from gurobipy.gurobipy import GRB\n",
    "from numpy.random import normal\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from generate_dataset import convert_dataset, generate_dataset\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On génère un dataset qui pourra être résolu par notre solveur. \n",
    "\n",
    "Il nous faut donc des valeurs cohérentes de notes par rapport aux coefficients des différentes matières ainsi que des frontières entre les différentes classes (Accepté, Refusé, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Les coeffs sont =  [0.27118644 0.38983051 0.18644068 0.15254237]\n",
      "\n",
      "Les frontières sont =  [[12. 17.]\n",
      " [ 2. 13.]\n",
      " [ 6.  8.]\n",
      " [ 9. 15.]]\n",
      "\n",
      "lambda =  0.820930125907707\n",
      "\n",
      "Les notes des élèves :\n",
      "[[13  8  2  8]\n",
      " [ 7  0  7 11]\n",
      " [12  2 10 13]\n",
      " [18 20 14  3]\n",
      " [17  2 14  0]\n",
      " [12 20  4  0]\n",
      " [18 19  7 20]\n",
      " [15 11 10  5]\n",
      " [11 13 14  0]\n",
      " [ 0 15  6  8]]\n",
      "\n",
      "Les classes des élèves :\n",
      "[0, 0, 1, 2, 1, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "X = convert_dataset(*generate_dataset(10, 4, 3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(X, students_count, subjects_count, classes_count, verbose=0):\n",
    "    \"\"\"\n",
    "    :param X: {list(np.array()[]} Liste de classes_count matrices de notes\n",
    "    :param students_count: {int} Nombre d'étudiants\n",
    "    :param subjects_count: {int} Nombre de matières\n",
    "    :param classes_count:  {int} Nombre de classes (ex: 2 pour {Accepté, Refusé})\n",
    "    :param verbose: {int} 0: prints nothing, 1:prints results, 2: debug level\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    R, *L, A = X\n",
    "\n",
    "    # Instanciation du modèle\n",
    "    m = Model(\"PL modeling\")\n",
    "\n",
    "    #------------------VARIABLES------------------\n",
    "\n",
    "    # Vecteur des coefficients des différentes matières\n",
    "    w = m.addMVar(shape=subjects_count, lb=0, ub=1, name=\"w\")\n",
    "\n",
    "    c_accepted = m.addMVar(shape=(len(A), subjects_count), lb=0, ub=1, name=\"c_accepted\")\n",
    "    c_refused = m.addMVar(shape=(len(R), subjects_count), lb=0, ub=1, name=\"c_refused\")\n",
    "\n",
    "    delta_accepted = m.addMVar(shape=(students_count, subjects_count), vtype=GRB.INTEGER, lb=0, ub=1,\n",
    "                               name=\"delta_accepted\")\n",
    "    delta_refused = m.addMVar(shape=(students_count, subjects_count), vtype=GRB.INTEGER, lb=0, ub=1,\n",
    "                              name=\"delta_refused\")\n",
    "\n",
    "    sigma_accepted = m.addMVar(shape=len(A), name=\"x\", vtype=GRB.CONTINUOUS)\n",
    "    sigma_refused = m.addMVar(shape=len(R), name=\"y\", vtype=GRB.CONTINUOUS)\n",
    "\n",
    "    lambd = m.addVar(name=\"lambda\", lb=0.5, ub=1)\n",
    "\n",
    "    b = m.addMVar(shape=subjects_count, name=\"b\", lb=0, ub=20)\n",
    "\n",
    "    alpha = m.addVar(name=\"alpha\")\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    epsilon = 0.01\n",
    "\n",
    "    M = 150\n",
    "\n",
    "    #------------------CONTRAINTES------------------\n",
    "\n",
    "    # Validation constraint with sigma\n",
    "    for index, student_point in enumerate(c_accepted):\n",
    "        m.addConstr(sum(student_point) - sigma_accepted[index] + epsilon == lambd)\n",
    "\n",
    "    # Refusal constraint with sigma\n",
    "    for index, student_point in enumerate(c_refused):\n",
    "        m.addConstr(sum(student_point) == lambd - sigma_refused[index])\n",
    "\n",
    "    # Alpha is inferior than all sigmas\n",
    "    for offset in (*sigma_accepted, *sigma_refused):\n",
    "        m.addConstr(alpha <= offset)\n",
    "\n",
    "    accepted_tuple = (c_accepted, delta_accepted, A)\n",
    "    refused_tuple = (c_refused, delta_refused, R)\n",
    "\n",
    "    for c, delta, grades in (accepted_tuple, refused_tuple):\n",
    "        for i in range(c.shape[0]):\n",
    "            for j in range(c.shape[1]):\n",
    "                m.addConstr(c[i, j] <= w[j])\n",
    "                m.addConstr(c[i, j] <= delta[i, j])\n",
    "                m.addConstr(c[i, j] >= delta[i, j] - 1 + w[j])\n",
    "                m.addConstr(M * delta[i, j] + epsilon >= grades[i, j] - b[j])\n",
    "                m.addConstr(M * (delta[i, j] - 1) <= grades[i, j] - b[j])\n",
    "\n",
    "    m.addConstr(sum(w) == 1)\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    if verbose == 0:\n",
    "        m.params.outputflag = 0\n",
    "\n",
    "    #Fonction objectif\n",
    "    m.setObjective(alpha, GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    m.optimize()\n",
    "    if verbose >= 1:\n",
    "        print(\"====== Model solved =====\")\n",
    "        print(f\"alpha = {alpha.X}\")\n",
    "        print(f\"lambda = {lambd.X}\")\n",
    "        print(f\"b = {b.X}\")\n",
    "\n",
    "        print(\"\\nLes coefficients de notre solution optimale sont :\")\n",
    "        print(f\"__________________\")\n",
    "\n",
    "        print(f\"| Matière  |coeff|\")\n",
    "\n",
    "        for index, coef in enumerate(w.X):\n",
    "            print(f\"|matière {index + 1} | {coef.round(2)} |\")\n",
    "        print(f\"__________________\")\n",
    "\n",
    "    return A, R, w.X, lambd.X, b.X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple 1 : \n",
    "\n",
    "20 élèves, 5 matières et 2 classes (Accepté ou Refusé) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Les coeffs sont =  [0.07017544 0.33333333 0.31578947 0.0877193  0.19298246]\n",
      "\n",
      "Les frontières sont =  [[ 3.]\n",
      " [ 6.]\n",
      " [13.]\n",
      " [17.]\n",
      " [13.]]\n",
      "\n",
      "lambda =  0.8116400429237574\n",
      "\n",
      "Les notes des élèves :\n",
      "[[19  6 10 17  3]\n",
      " [ 9 20  2 11  8]\n",
      " [ 1  1 14 11 12]\n",
      " [ 9  9  9 18  2]\n",
      " [ 5 12 17  8  7]\n",
      " [10  4  4  4 17]\n",
      " [19  0 20 13  4]\n",
      " [11 10 15 20 12]\n",
      " [20 10  8  7  1]\n",
      " [ 4  8 18 12  5]\n",
      " [16 17 18  5 10]\n",
      " [ 1  8  2  5 12]\n",
      " [13 13 20 12 16]\n",
      " [19  7 12  7 18]\n",
      " [ 8  5  2  2  5]\n",
      " [14  0 17  2  2]\n",
      " [ 9 15  1 19  8]\n",
      " [ 4 19  6 20 17]\n",
      " [14 19  7  0 17]\n",
      " [ 7 17 14 15  3]]\n",
      "\n",
      "Les classes des élèves :\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "X = convert_dataset(*generate_dataset(20, 5, 2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (win64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 541 rows, 332 columns and 1285 nonzeros\n",
      "Model fingerprint: 0x94cc7c85\n",
      "Variable types: 132 continuous, 200 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [5e-01, 2e+01]\n",
      "  RHS range        [1e-02, 2e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 34 rows and 120 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 507 rows, 212 columns, 1217 nonzeros\n",
      "Variable types: 107 continuous, 105 integer (100 binary)\n",
      "\n",
      "Root relaxation: objective 5.050000e-01, 177 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0       0.5050000    0.50500  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (379 simplex iterations) in 0.03 seconds (0.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 0.505 -0 \n",
      "No other solutions better than 0.505\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.050000000000e-01, best bound 5.050000000000e-01, gap 0.0000%\n",
      "====== Model solved =====\n",
      "alpha = 0.505\n",
      "lambda = 0.505\n",
      "b = [ 6.99  0.   19.99  7.99  4.99]\n",
      "\n",
      "Les coefficients de notre solution optimale sont :\n",
      "__________________\n",
      "| Matière  |coeff|\n",
      "|matière 1 | 0.0 |\n",
      "|matière 2 | 0.0 |\n",
      "|matière 3 | 1.0 |\n",
      "|matière 4 | 0.0 |\n",
      "|matière 5 | 0.0 |\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "accepted, refused, weigths, lambd, b = solve(X, 20, 5, 2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "print((accepted >= b) @ weigths.T >= lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False  True False False False False False\n",
      " False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print((refused >= b) @ weigths.T >= lambd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Conclusion :**\n",
    "\n",
    "Avec 2 classes (Accepté, Refusé), notre MRSort fonctionne et nous renvoie une solution faisable pour notre dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Influence du nombre d'instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def compute_performance(test_dataset, stats_df, parameter_name, parameter_value, noise=0):\n",
    "    \"\"\"\n",
    "    Calcul les performance d'un modèle de poids sur un dataset de test donné\n",
    "    :param test_dataset: {(np.array(), classe} Dataset de test\n",
    "    :param stats_df: {pd.Dataframe} Dataframe dans lequel les stats seront ajoutées\n",
    "    :param parameter_name: {str} Nom du paramètre évalué\n",
    "    :param parameter_value: {int} Valeur du paramètre évalué\n",
    "    :return: {pd.Dataframe} Dataframe contenant les statistiques du modèle\n",
    "    \"\"\"\n",
    "    X_test, y_test = list(zip(*test_dataset))\n",
    "\n",
    "    X_test_noised = np.array(X_test) + normal(0, noise, np.array(X_test).shape)\n",
    "\n",
    "    pred = (X_test_noised >= b) @ weights.T >= lambd\n",
    "\n",
    "    confusion_mat = confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "    TP = confusion_mat[0, 0]\n",
    "    TN = confusion_mat[1, 1]\n",
    "    FP = confusion_mat[0, 1]\n",
    "    FN = confusion_mat[1, 0]\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    duration = end - start\n",
    "    raw_stats = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"accuracy\": (TP + TN) / (TP + TN + FP + FN),\n",
    "        \"F1 score\": 2 * (precision * recall) / (precision + recall),\n",
    "        \"duration (in s)\": duration\n",
    "    }\n",
    "\n",
    "    for key, value in raw_stats.items():\n",
    "        stats_df = stats_df.append({\"type\": key, \"value\": value, parameter_name: parameter_value},\n",
    "                                   ignore_index=True)\n",
    "\n",
    "    return stats_df, duration\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 60 110 160 210 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7564/3517521493.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mperf_counter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m         accepted, refused, weights, lambd, b = solve(train, students_count, subjects_count,\n\u001B[1;32m---> 23\u001B[1;33m                                                      classes_count, verbose=0)\n\u001B[0m\u001B[0;32m     24\u001B[0m         \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mperf_counter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7564/732730348.py\u001B[0m in \u001B[0;36msolve\u001B[1;34m(X, students_count, subjects_count, classes_count, verbose)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 80\u001B[1;33m     \u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     81\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mverbose\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"====== Model solved =====\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "graphs_directories = \"graphs\"\n",
    "\n",
    "elapsed_time = 0\n",
    "students_count = 10\n",
    "subjects_count = 4\n",
    "classes_count = 2\n",
    "stats = pd.DataFrame(columns=[\"type\", \"value\", \"students_count\"])\n",
    "\n",
    "while elapsed_time < 12:\n",
    "    print(students_count, end=\" \")\n",
    "    for i in range(12):\n",
    "        dataset = generate_dataset(students_count * 2, subjects_count, classes_count, verbose=0)\n",
    "        dataset = list(zip(list(dataset[0]), dataset[1]))\n",
    "\n",
    "        random.shuffle(dataset)\n",
    "        train = dataset[:len(dataset) // 2]\n",
    "        test = dataset[len(dataset) // 2:]\n",
    "\n",
    "        train = convert_dataset(*list(zip(*train)), classes_count)\n",
    "\n",
    "        start = perf_counter()\n",
    "        accepted, refused, weights, lambd, b = solve(train, students_count, subjects_count,\n",
    "                                                     classes_count, verbose=0)\n",
    "        end = perf_counter()\n",
    "\n",
    "        stats, elapsed_time = compute_performance(test, stats, \"students_count\", students_count)\n",
    "\n",
    "    students_count += 50\n",
    "aggregated_stats = stats.groupby([\"students_count\", \"type\"]).agg({\"value\": \"mean\"}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(aggregated_stats[~(aggregated_stats[\"type\"] == \"duration (in s)\")], x=\"students_count\", y=\"value\",\n",
    "              color=\"type\",\n",
    "              title=f\"Model performance depending on students_count with subjects_counts={subjects_count}\")\n",
    "\n",
    "if not os.path.exists(graphs_directories):\n",
    "    os.mkdir(graphs_directories)\n",
    "fig.show()\n",
    "\n",
    "try:\n",
    "    fig.write_image(f\"{graphs_directories}/gurobi_perf_students.png\")\n",
    "except:\n",
    "    print(\"Please install kaleido (pip install -U kaleido for static image export)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(aggregated_stats[(aggregated_stats[\"type\"] == \"duration (in s)\")], x=\"students_count\", y=\"value\",\n",
    "              color=\"type\", title=f\"Training duration depending on students_count with subject_counts={subjects_count}\")\n",
    "fig.show()\n",
    "try:\n",
    "    fig.write_image(f\"{graphs_directories}/gurobi_duration_students.png\")\n",
    "except:\n",
    "    print(\"Please install kaleido (pip install -U kaleido for static image export)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Influence du nombre de critères"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(columns=[\"type\", \"value\", \"subjects_count\"])\n",
    "\n",
    "subjects_count = 2\n",
    "students_count = 600\n",
    "elapsed_time = 0\n",
    "\n",
    "while elapsed_time < 20:\n",
    "    for i in range(12):\n",
    "        dataset = generate_dataset(students_count * 2, subjects_count, classes_count, verbose=0)\n",
    "        dataset = list(zip(list(dataset[0]), dataset[1]))\n",
    "\n",
    "        random.shuffle(dataset)\n",
    "        train = dataset[:len(dataset) // 2]\n",
    "        test = dataset[len(dataset) // 2:]\n",
    "\n",
    "        train = convert_dataset(*list(zip(*train)), classes_count)\n",
    "\n",
    "        start = perf_counter()\n",
    "        accepted, refused, weights, lambd, b = solve(train, students_count, subjects_count,\n",
    "                                                     classes_count, verbose=0)\n",
    "        end = perf_counter()\n",
    "\n",
    "        stats, elapsed_time = compute_performance(test, stats, \"subjects_count\", subjects_count)\n",
    "\n",
    "    subjects_count += 1\n",
    "aggregated_stats = stats.groupby([\"subjects_count\", \"type\"]).agg({\"value\": \"mean\"}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(aggregated_stats[~(aggregated_stats[\"type\"] == \"duration (in s)\")], x=\"subjects_count\", y=\"value\",\n",
    "              color=\"type\", title=f\"Model performance depending on subjects_count with students_count={students_count}\")\n",
    "\n",
    "fig.show()\n",
    "try:\n",
    "    fig.write_image(f\"{graphs_directories}/gurobi_perf_subjects.png\")\n",
    "except:\n",
    "    print(\"Please install kaleido (pip install -U kaleido for static image export)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(aggregated_stats[(aggregated_stats[\"type\"] == \"duration (in s)\")], x=\"subjects_count\", y=\"value\",\n",
    "              color=\"type\",\n",
    "              title=f\"Training duration depending on subject_counts with students_counts={students_count}\")\n",
    "fig.show()\n",
    "try:\n",
    "    fig.write_image(f\"{graphs_directories}/gurobi_duration_subjects.png\")\n",
    "except:\n",
    "    print(\"Please install kaleido (pip install -U kaleido for static image export)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Influence du bruit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(columns=[\"type\", \"value\", \"subjects_count\"])\n",
    "\n",
    "subjects_count = 4\n",
    "students_count = 500\n",
    "elapsed_time = 0\n",
    "\n",
    "for noise in np.arange(0, 20, 0.3):\n",
    "    for i in range(8):\n",
    "        if i == 0:\n",
    "            print(f\"{noise:.1f}\", end=\" \")\n",
    "        dataset = generate_dataset(students_count * 2, subjects_count, classes_count, verbose=0)\n",
    "        dataset = list(zip(list(dataset[0]), dataset[1]))\n",
    "\n",
    "        random.shuffle(dataset)\n",
    "        train = dataset[:len(dataset) // 2]\n",
    "        test = dataset[len(dataset) // 2:]\n",
    "\n",
    "        train = convert_dataset(*list(zip(*train)), classes_count)\n",
    "\n",
    "        start = perf_counter()\n",
    "        accepted, refused, weights, lambd, b = solve(train, students_count, subjects_count, classes_count, verbose=0)\n",
    "        end = perf_counter()\n",
    "        stats, elapsed_time = compute_performance(dataset, stats, \"écart-type\", noise, noise=noise)\n",
    "aggregated_stats = stats.groupby([\"écart-type\", \"type\"]).agg({\"value\": \"mean\"}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(aggregated_stats[~(aggregated_stats[\"type\"] == \"duration (in s)\")], x=\"écart-type\", y=\"value\",\n",
    "              color=\"type\",\n",
    "              title=f\"Model performance with noise applied thanks to a centered normal <br> law with students_count={students_count} and subjects_count={subjects_count}\")\n",
    "\n",
    "fig.show()\n",
    "try:\n",
    "    fig.write_image(f\"{graphs_directories}/gurobi_perf_noise.png\")\n",
    "except:\n",
    "    print(\"Please install kaleido (pip install -U kaleido) for static image export\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}